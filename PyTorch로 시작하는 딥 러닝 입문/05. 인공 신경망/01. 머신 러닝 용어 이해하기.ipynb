{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. 머신 러닝 모델의 평가**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG\">\n",
    "\n",
    "실제 모델을 평가하기 위해선 데이터를 훈련용, 검증용, 테스트용 세 가지로 분리하는 것이 일반적입니다. 우리는 앞서 훈련용과 테스트용으로만 나누어 진행했습니다. 그렇다면 왜 훈련용 데이터를 다시 훈련용과 검증용으로 나눌까요?\n",
    "\n",
    "검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도입니다. 더 정확히는 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도입니다. 하이퍼파라미터(초매개변수)는 값에 따라서 모델의 성능에 영향을 주는 매개변수들을 말합니다. 반면 가중치, 편향과 같이 학습을 통해 바뀌는 것을 매개변수라고 합니다.\n",
    "\n",
    "그렇기에 하이퍼파라미터는 사용자가 직접 정해줄 수 있는 변수입니다. 경사 하강법에서 학습률, 딥러닝에서 은닉층의 수, 뉴런의 수, 드롭아웃 비율 등이 이에 해당합니다. 반대로 매개변수는 사용자가 결정하지 못하고 모델이 학습을 통해 얻는 값입니다. \n",
    "\n",
    "훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝합니다. 또한 이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 맞춰가기 시작합니다.\n",
    "\n",
    "하이퍼파라미터 튜닝이 끝났다면 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않습니다. 모델이 검증용 데이터에 대해서도 어느정도 최적화가 되었기 때문입니다. 그렇기에 모델이 아직 한 번도 접하지 못한 데이터로 테스트 하는 것이 바람직합니다. \n",
    "\n",
    "비유하면 훈련 데이터는 문제지, 검증 데이터는 모의고사, 테스트 데이터는 수능이라고 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. 분류(Classification)와 회귀(Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전부는 아니지만 머신 러닝의 많은 문제는 분류 또는 회귀 문제데 속합니다. 앞서 배운 선형 회귀는 회귀 문제에 대해서, 로지스틱 회귀는 분류 문제에 대해서 학습합니다. \n",
    "\n",
    "### **2.1 이진 분류 문제(Binary Classification)**\n",
    "이진 분류는 주어진 입력에 대해 둘 중 하나의 답을 정하는 문제입니다. 합격과 불합격, 스팸 메일과 그렇지 않은 메일, 정상과 비정상을 판단하는 문제들이 있습니다\n",
    "\n",
    "### **2.2 다중 클래스 분류(Multi-class Classification)**\n",
    "다중 클래스 분류는 주어진 입력에 대해서 세 개 이상의 정해진 선택지 중 답을 정하는 문제입니다. 동물이 있다면 주어진 문제의 동물이 개인지, 고양이인지, 코끼리인지 찾는 문제가 이에 속합니다. 이 때, 동물의 종류, 즉 선택지들을 주로 카테고리(혹은 범주나 클래스)라고 합니다.\n",
    "\n",
    "### **2.3 회귀 문제(Regression)**\n",
    "회귀 문제는 분류 문제와 다르게 연속된 값들을 결과로 가집니다. 예를 들어 시험 성적을 공부 시간으로 예측하는 문제 등이 있습니다. 그 외에도 시계열 데이터를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. 지도 학습(Supervised Learning)과 비지도 학습(Unsupervised Learning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신 러닝을 크게 지도 학습과 비지도 학습으로 나눕니다.\n",
    "\n",
    "### **3.1 지도 학습**\n",
    "지도 학습이란 레이블이라는 정답과 함께 학습하는 것을 말합니다. 이때 기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습을 하게 됩니다.\n",
    "\n",
    "### **3.2 비지도 학습**\n",
    "비지도 학습은 기본적으로 목적 데이터(또는 레이블)이 없는 학습 방법입니다. 대표적으로 군집(Clustering)이나 차원 축소와 같은 학습 방법들을 비지도 학습이라고 합니다.\n",
    "\n",
    "### **3.3 강화 학습**\n",
    "강화 학습은 어떤 환경 내에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Sample과 Feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://wikidocs.net/images/page/35821/n_x_m.PNG\">\n",
    "\n",
    "머신 러닝에서는 하나의 데이터(위 그림에서 행)를 sample이라고 부릅니다. (데이터베이스에서는 레코드라고 부르는 단위입니다.) 그리고 종속 변수 $y$를 예측하기 위한 각각의 독립 변수 $x$를 feature라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. 혼동 행렬(Confusion Matrix)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 합니다. 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않습니다. 이를 알기 위해 혼동 행렬을 사용합니다.\n",
    "\n",
    "예를 들어 positive와 negative를 구분하는 이진 분류가 있다고 했을 때, 혼동 행렬은 다음과 같습니다. 각 열을 예측값을 나타내며, 각 행은 실제값을 나타냅니다. \n",
    "\n",
    "|                     |Positive로 예측  | Negative로 예측 |\n",
    "|---                  |---                 |---                  |\n",
    "|실제 Positive   | $$TP(True Positive)$$         |    $$FN(False Negative)$$       |\n",
    "|실제 Negative    |   $$FP(False Positive)$$       |   $$TN(True Negative)$$        | \n",
    "\n",
    "True는 정답을 맞춘 경우고 False는 정답을 못 맞춘 경우입니다. 그리고 positive와 negative는 예측값입니다. \n",
    "\n",
    "이 개념을 사용하면 새로운 개념인 정밀도(Precision)과 재현률(Recall)을 구할 수 있습니다.\n",
    "\n",
    "### **5.1 정밀도(Precision)** \n",
    "정밀도는 positive이라고 대답한 전체 케이스에 대한 TP의 비율입니다. 즉, 실제 positive인 데이터 중에서 얼마나 positive를 예측했는지 나타냅니다.\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "### **5.2 재현률(Recall)**\n",
    "재현률은 실제값이 positive인 데이터의 전체 개수에 대한 TP의 비율입니다. 즉, positive인 데이터 중에서 얼마나 positive인지를 예측했는지 나타냅니다.\n",
    "\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. 과적합(Overfitting)과 과소 적합(Underfitting)**\n",
    "머신 러닝에서 과적합이란 훈련 데이터를 과하게 학습한 경우를 말합니다. 훈련 데이터만 과하게 학습하여 실제 데이터에 대해서는 정확도가 좋지 못한 경우입니다. 과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아집니다. 아래의 그래프는 과적합 상황에서 발생할 수 있는 훈련 횟수에 따른 훈련 데이터의 오차와 테스트 데이터의 오차 변화를 보여줍니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png\">\n",
    "\n",
    "X축의 epoch는 전체 훈련 데이터에 대한 훈련 횟수를 의미합니다. 위의 그래프는 epoch가 3~4를 넘어가면 과적합이 발생합니다. 그렇기에 테스트 데이터의 오차가 증가하기 전이나, 정확도가 감소하기 전에 훈련을 멈추는 것이 바람직합니다.\n",
    "\n",
    "반대로 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 과소적합이라고 합니다. 훈련 자체가 부족한 상태이므로 테스트 데이터와 훈련 데이터에서 모두 정확도가 낮습니다.\n",
    "\n",
    "이러한 현상을 과적합과 과소적합이라고 부르는 이유는 머신 러닝에서 학습, 훈련하는 과정을 적합(fitting)이라고 하기 때문입니다. 적합이라고 부르는 이유는 모델이 주어진 데이터에 대해서 적합해지는 과정이기 떄문입니다.\n",
    "\n",
    "딥 러닝을 할 때, 과적합을 막을 수 있는 드롭아웃, 조기 종료와 같은 몇 가지 방법이 존재합니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
