{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 기본 작업**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.legacy import data, datasets\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24995675190>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 훈련 데이터에 대한 이해**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1) 필드 정의하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에 사용할 데이터는 총 3개의 열, 즉 다시 말해 3개의 필드를 가지고 있습니다. 왜냐하면 레이블이 총 2개이기 때문인데 이 중 1개만 사용할 것이지만 원활하게 데이터를 불러오기 위해서 일단은 3개 필드 모두 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 필드 정의\n",
    "TEXT = data.Field(lower = True)\n",
    "UD_TAGS = data.Field(unk_token=None)\n",
    "PTB_TAGS = data.Field(unk_token=None)\n",
    "\n",
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2) 데이터셋 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 토치텍스트에서 제공하는 훈련 데이터를 불러오는 동시에 데이터셋을 만들어보겠습니다. 훈련 데이터, 검증 데이터, 테스트 데이터를 각각 나눠서 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터, 검증 데이터, 테스트 데이터의 크기를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 개수 : 12543\n",
      "검증 샘플의 개수 : 2002\n",
      "테스트 샘플의 개수 : 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"훈련 샘플의 개수 : {len(train_data)}\")\n",
    "print(f\"검증 샘플의 개수 : {len(valid_data)}\")\n",
    "print(f\"테스트 샘플의 개수 : {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 생성하였으니 훈련 데이터의 필드들을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': <torchtext.legacy.data.field.Field object at 0x0000024991E8DCA0>, 'udtags': <torchtext.legacy.data.field.Field object at 0x0000024991E8D280>, 'ptbtags': <torchtext.legacy.data.field.Field object at 0x0000024991E8D9A0>}\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터의 3개의 필드 확인\n",
    "print(train_data.fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터의 첫번째 샘플에서 text와 두 개의 레이블을 모두 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 훈련 샘플의 text 필드\n",
    "print(vars(train_data.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 훈련 샘플의 udtags 필드\n",
    "print(vars(train_data.examples[0])['udtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 훈련 샘플의 ptbdtags 필드\n",
    "print(vars(train_data.examples[0])['ptbtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3) Vocabulary 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 집합을 생성해보겠습니다. 그리고 단어 집합을 생성 시에 사전 훈련된 워드 임베딩인 GloVe를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최소 허용 빈도\n",
    "MIN_FREQ = 5\n",
    "\n",
    "# 사전 훈련된 워드 임베딩 GloVe 다운로드\n",
    "TEXT.build_vocab(train_data, min_freq=MIN_FREQ, vectors=\"glove.6B.100d\")\n",
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상위 빈도 수 20개의 단어만 출력해보겠습니다. TEXT.vocab.freqs.most_common(20)을 통해 출력할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 9076), ('.', 8640), (',', 7021), ('to', 5137), ('and', 5002), ('a', 3782), ('of', 3622), ('i', 3379), ('in', 3112), ('is', 2239), ('you', 2156), ('that', 2036), ('it', 1850), ('for', 1842), ('-', 1426), ('have', 1359), ('\"', 1296), ('on', 1273), ('was', 1244), ('with', 1216)]\n"
     ]
    }
   ],
   "source": [
    "# 상위 빈도수 20개 단어\n",
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영어는 보통 the가 빈도수가 가장 높습니다. 토치텍스트는 기본적으로 빈도수가 가장 높은 단어부터 작은 숫자를 부여합니다. 물론 < unk>는 0번, < pad>는 1번으로 자동 부여됩니다.\n",
    "\n",
    "상위 정수 인덱스를 가진 10개의 단어를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', '.', ',', 'to', 'and', 'a', 'of', 'i']\n"
     ]
    }
   ],
   "source": [
    "# 상위 정수 인덱스 단어 10개 출력\n",
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 레이블의 단어 집합에 대해서 빈도수가 가장 높은 단어들과 그 빈도수를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 34781), ('PUNCT', 23679), ('VERB', 23081), ('PRON', 18577), ('ADP', 17638), ('DET', 16285), ('PROPN', 12946), ('ADJ', 12477), ('AUX', 12343), ('ADV', 10548), ('CCONJ', 6707), ('PART', 5567), ('NUM', 3999), ('SCONJ', 3843), ('X', 847), ('INTJ', 688), ('SYM', 599)]\n"
     ]
    }
   ],
   "source": [
    "# 상위 빈도순으로 udtags 출력\n",
    "print(UD_TAGS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'NOUN', 'PUNCT', 'VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'ADJ', 'AUX', 'ADV', 'CCONJ', 'PART', 'NUM', 'SCONJ', 'X', 'INTJ', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "# 상위 정수 인덱스 순으로 출력\n",
    "print(UD_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블에 속한 단어들의 분포를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_percentage(tag_conuts): # 태그 레이블의 분포를 확인하는 함수\n",
    "    total_count = sum([count for tag, count in tag_conuts])\n",
    "    tag_counts_percentage = [(tag, count, count/total_count) for tag, count in tag_conuts]\n",
    "    return tag_counts_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag  Occurences Percentage\n",
      "\n",
      "NOUN\t34781\t17.0%\n",
      "PUNCT\t23679\t11.6%\n",
      "VERB\t23081\t11.3%\n",
      "PRON\t18577\t 9.1%\n",
      "ADP\t17638\t 8.6%\n",
      "DET\t16285\t 8.0%\n",
      "PROPN\t12946\t 6.3%\n",
      "ADJ\t12477\t 6.1%\n",
      "AUX\t12343\t 6.0%\n",
      "ADV\t10548\t 5.2%\n",
      "CCONJ\t6707\t 3.3%\n",
      "PART\t5567\t 2.7%\n",
      "NUM\t3999\t 2.0%\n",
      "SCONJ\t3843\t 1.9%\n",
      "X\t847\t 0.4%\n",
      "INTJ\t688\t 0.3%\n",
      "SYM\t599\t 0.3%\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag  Occurences Percentage\\n\")\n",
    "for tag, count, percent in tag_percentage(UD_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t{count}\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4) 데이터로더 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터로더를 만들겠습니다. 배치 크기는 64로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 미니 배치만 꺼내서 미니 배치의 구성, 크기, text를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.legacy.data.batch.Batch of size 64 from UDPOS]\n",
       "\t[.text]:[torch.LongTensor of size 46x64]\n",
       "\t[.udtags]:[torch.LongTensor of size 46x64]\n",
       "\t[.ptbtags]:[torch.LongTensor of size 46x64]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_iterator))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape # (시퀀스 길이 x 배치 크기), batch_first=Ture를 안 했기에 배치 크기가 두번째 차원이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 732,  167,    2,  ...,    2,   59,  668],\n",
       "        [  16,  196,  133,  ..., 2991,   46,    1],\n",
       "        [   1,   29,   48,  ..., 1582,   12,    1],\n",
       "        ...,\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1],\n",
       "        [   1,    1,    1,  ...,    1,    1,    1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 모델 구현하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 구현하겠습니다. 기본적으로 대다대 RNN을 사용할텐데, 일단 양방향 여부와 층의 개수는 변수로 두겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 모델에서는 batch_first=True를 사용하지 않으므로 배치 차원이 맨 앞이 아님\n",
    "class RNNPOSTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # text = [sent len, batch size]\n",
    "        embedd = self.dropout(self.embedding(text))\n",
    "        \n",
    "        # embedded = [sent len, batch size, emb dim]\n",
    "        outputs, (hidden, cell) = self.rnn(embedd)\n",
    "        \n",
    "        # output = [sent len, batch size, hid dim * n directions]\n",
    "        # hidden / cell = [n layers * n directions, batch size, hid dim]\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        # predictions = [sent len, batch size, output dim]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 클래스로부터 모델 객체로 생성 시, 양방향 여부를 True로 주고, 층의 개수를 2로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = RNNPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,027,510 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 개수 출력\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 102만 7천 5백 10개의 파라미터가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. 사전 훈련된 워드 임베딩 사용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급했듯이, 이번 챕터에서는 사전 훈련된 워드 임베딩인 GloVe를 사용합니다. 이를 위해서 토치텍스트의 단어 집합 생성 시에 저장해두었던 GloVe 임베딩을 nn.Embedding()에 연결해줄 필요가 있습니다. 우선 단어 집합의 단어들에 맵핑된 사전 훈련된 워드 임베딩을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3921, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 집합에 존재하는 총 3,921개의 단어에 대해서 100차원의 벡터가 맵핑되어져 있습니다. 이제 nn.Embedding()에 이를 연결시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1020,  0.7700,  0.1169,  ..., -0.1416, -0.1932, -0.4225],\n",
       "        [-0.0263,  0.0179, -0.5016,  ..., -0.8688,  0.9409, -0.2882],\n",
       "        [ 0.1519,  0.4712,  0.0895,  ..., -0.4702, -0.3127,  0.1078]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings) # 임베딩 벡터값 copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 < unk> 토큰의 인덱스와 < pad> 토큰의 인덱스를 저장해줍니다. 물론 각각 0과 1 인덱스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "print(UNK_IDX)\n",
    "print(PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 임의로 0번과 1번 단어에는 0벡터를 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [-0.1020,  0.7700,  0.1169,  ..., -0.1416, -0.1932, -0.4225],\n",
      "        [-0.0263,  0.0179, -0.5016,  ..., -0.8688,  0.9409, -0.2882],\n",
      "        [ 0.1519,  0.4712,  0.0895,  ..., -0.4702, -0.3127,  0.1078]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM) # 0번 임베딩 벡터에 0값을 채운다.\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM) # 1번 임베딩 벡터에 1값을 채운다.\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAD 토큰과 UNK 토큰의 임베딩 벡터값이 0인 것을 볼 수 있습니다. 사전 훈련된 워드 임베딩을 사용할 준비가 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. 옵티마이저와 비용 함수 구현하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저 설계 전에 레이블 데이터의 패딩 토큰의 인덱스도 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "print(TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0인 것을 확인할 수 있습니다. 이를 하는 이유는 아래 비용 함수를 선택할 때 인자로 주기 위함입니다. 이제 옵티마이저를 설정합니다. 여기서는 Adma을 택했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 함수로 크로스엔트로피 함수를 선택합니다. 이때 레이블 데이터의 패딩 토큰은 비용 함수의 연산에 포함시키지도 않도록 레이블 데이터의 패딩 토큰을 무시하라고 기재해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 모델은 훈련되지 않은 상태이지만 모델이 입력값을 넣어 출력(예측값)의 크기를 확인해보겠습니다. 여기서 넣는 입력값은 앞에서 꺼내두었던 첫번째 배치입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 64, 18])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46 x 64 x 18은 각각 (첫번째 배치의 시퀀스 길이 x 배치 크기 x 레이블 단어장의 크기)에 해당됩니다. 주의할 점은 현재 batch_first를 해주지 않아 배치 크기가 맨 앞 차원이 아니라는 것입니다. 또한 46은 첫번째 배치의 시퀀스 길이일뿐, 다른 배치들은 시퀀스 길이가 다를 수 있습니다.\n",
    "\n",
    "이제 예측값에 대해서 시퀀스 길이와 배치 길이를 모두 펼쳐주는 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2944, 18])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.view(-1, prediction.shape[-1])\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크기가 (2994 x 18)이 됩니다. 이번에는 첫번째 배치의 레이블 데이터의 크기를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.udtags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46 x 64는 (첫번째 배치의 시퀀스 길이 x 배치 크기)에 해당됩니다. 이를 펼쳐보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2944])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.udtags.view(-1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2,944의 크기를 가지게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. 훈련과 평가하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"미니 배치에 대한 정확도 출력\"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "\n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #text = [sent len, batch size]     \n",
    "        predictions = model(text)\n",
    "\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        predictions = predictions.view(-1, predictions.shape[-1]) # #predictions = [sent len * batch size, output dim]\n",
    "        tags = tags.view(-1) # tags = [sent len * batch_size]\n",
    "\n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        loss = criterion(predictions, tags)\n",
    "\n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.udtags\n",
    "\n",
    "            predictions = model(text)\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            loss = criterion(predictions, tags)\n",
    "\n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 1.090 | Train Acc: 66.15%\n",
      "\t Val. Loss: 0.661 |  Val. Acc: 79.39%\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.387 | Train Acc: 87.81%\n",
      "\t Val. Loss: 0.535 |  Val. Acc: 83.34%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.303 | Train Acc: 90.21%\n",
      "\t Val. Loss: 0.491 |  Val. Acc: 84.38%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.264 | Train Acc: 91.41%\n",
      "\t Val. Loss: 0.460 |  Val. Acc: 85.26%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.237 | Train Acc: 92.24%\n",
      "\t Val. Loss: 0.448 |  Val. Acc: 85.13%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.219 | Train Acc: 92.75%\n",
      "\t Val. Loss: 0.433 |  Val. Acc: 85.97%\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.204 | Train Acc: 93.33%\n",
      "\t Val. Loss: 0.421 |  Val. Acc: 86.29%\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.191 | Train Acc: 93.72%\n",
      "\t Val. Loss: 0.413 |  Val. Acc: 86.37%\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.178 | Train Acc: 94.04%\n",
      "\t Val. Loss: 0.409 |  Val. Acc: 86.47%\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.169 | Train Acc: 94.36%\n",
      "\t Val. Loss: 0.410 |  Val. Acc: 86.60%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.412 |  Test Acc: 87.26%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
