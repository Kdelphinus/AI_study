{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터는 문자보다 숫자를 잘 처리할 수 있습니다. 그렇기에 자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법들이 있습니다. 원-핫 인코딩은 그 많은 기법 중에서 가장 기본적인 표현 방법입니다. \n",
    "\n",
    "원-핫 인코딩을 배우기 전에 먼저 **단어 집합(vocabulary)** 을 알아야 합니다. 단어 집합에서는 기본적으로 book과 books와 같이 단어의 변형 형태도 다른 단어로 간주합니다. \n",
    "\n",
    "원-핫 인코딩을 위해서 먼저 해야할 일은 단어 집합을 만드는 일입니다. 텍스트의 모든 단어를 중복을 허용하지 않고 모아놓으면 이를 단어 집합이라고 합니다. 그리고 이 단어 집합에 고유한 숫자를 부여하는 정수 인코딩을 진행합니다. 이렇게 단어 별로 고유한 정수 인덱스를 부여하고 숫자로 바뀐 단어 벡터들을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 원-핫 인코딩(One-hot encoding)이란?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을, 다른 인덱스엔 0을 부여하는 단어의 벡터 표현 방식입니다. 간단하게 (1) 각 단어에 고유한 인덱스를 부여하고 (2) 표현하고 싶은 단어의 인덱스 위치엔 1, 나머지는 0을 부여합니다. \n",
    "\n",
    "이해를 위해 한국어 문장을 예제로 원-핫 벡터를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "token = okt.morphs(\"나는 자연어 처리를 배운다\")\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "konlpy의 Okt 형태소 분석기를 통해서 우선 문장에 대해서 토큰화를 수행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {}\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca] = len(word2index)\n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 토큰에 대해서 고유한 인덱스를 부여했습니다. 지금은 문장이 짧기 때문에 각 단어의 빈도수를 고려하지 않았지만, 빈도수 순대로 단어를 정렬하고 고유한 인덱스를 부여하는 작업이 사용되기도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "    one_hot_vector = [0] * len(word2index)\n",
    "    index = word2index[word]\n",
    "    one_hot_vector[index] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰을 입력하면 원-핫 벡터를 만드는 함수를 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"자연어\", word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"자연어\"는 단어 집합에서 인덱스가 2이므로, 원-핫 벡터의 인덱스 2의 값만 1이고 나머지가 0인 벡터가 나옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 원-핫 인코딩의 한계**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 방식은 단어의 개수가 늘어날수록, 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점이 있습니다. 즉, 벡터의 차원이 계속 늘어납니다. 이는 단어가 많아질수록 저장 공간 측면에서 매우 비효율적인 방법입니다. \n",
    "\n",
    "또한 원-핫 벡터는 단어의 유사도를 표현하지 못합니다. 강아지, 개, 냉장고라는 단어가 있을 때, 강아지와 개가 유사하다는 것을 원-핫 벡터로는 표현할 수 없습니다. \n",
    "\n",
    "단어의 유사성을 알 수 없는 것은 연관 검색 등, 검색 시스템에서 치명적입니다. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5551ce9075601fcac27a6f74f4f40e8508e3c8b600b16b2dab97cda04d068487"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('konlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
