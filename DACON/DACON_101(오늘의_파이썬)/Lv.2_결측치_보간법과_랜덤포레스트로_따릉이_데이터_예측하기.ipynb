{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 전처리"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 파이썬 결측치 대체 평균"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\".data/train.csv\")\n",
    "test = pd.read_csv(\".data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "train_null = list(zip(train.columns.to_list(), train.isnull().sum()))\n",
    "for col, n in train_null:\n",
    "\tif n:\n",
    "\t\ttrain.fillna({col:int(train[col].mean())}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### interpolate() method"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "따릉이 데이터의 경우, feature들은 기상정보들이며 데이터의 순서는 시간 순서이다. 그렇기에 결측치들을 이전 행(직전 시간)과 이후 행(직후 시간)의 평균으로 보간하는 것이 합리적이다. 그렇기에 interpolate()로 결측치를 대체해야 한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\".data/train.csv\")\n",
    "test = pd.read_csv(\".data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "train_null = list(zip(train.columns.to_list(), train.isnull().sum()))\n",
    "for i, n in train_null:\n",
    "\tif n: train.interpolate(inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델링"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 랜덤포레스트 개념, 선언"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "``` 랜덤포레스트 ``` 는 여러 개의 의사결정나무를 만들어서 이들의 평균으로 예측의 성능을 높이는 방법이다. 이렇게 여러 개의 모델들을 이용해 성능을 높이는 기법을 ``` 앙상블(Ensemble) ``` 기법이라고 한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 랜덤포레스트를 평가척도에 맞게 학습"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "랜덤포레스트의 여러 옵션 중 criterion 옵션은 어떠한 평가척도를 기준으로 훈련할 것인지 정할 수 있다.\n",
    "\n",
    "따릉이 대회의 평가지표는 RMSE이다. RMSE는 MSE 평가지표에 루트를 씌운 것으로 모델을 선언할 때, ``` criterion='mse' ``` 옵션으로 구현할 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$ MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y})^2 $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(criterion='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "X_train = train.drop(['count'], axis=1)\n",
    "Y_train = train['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor(criterion='mse')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 튜닝"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 랜덤포레스트 변수중요도 확인"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fit()으로 학습된 모델은 feature_importances_ 속성(attribute)으로 변수의 중요도를 파악할 수 있다. 변수의 중요도란 예측 변수를 결정할 때, 각 피쳐가 얼마나 중요한 역할을 하는지에 대한 척도이다.\n",
    "\n",
    "- 변수의 중요도: 예측변수를 결정할 때, 각 피쳐가 얼마나 중요한 역할을 하는지에 대한 척도\n",
    "\n",
    "정의에 따라 변수의 중요도가 낮다면 해당 피쳐를 제거하는 것이 모델의 성능을 높일 수도 있다는 의미이다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0.02519611982335789\n",
      "hour: 0.5916669341062244\n",
      "hour_bef_temperature: 0.17955279066338872\n",
      "hour_bef_precipitation: 0.0189562829536924\n",
      "hour_bef_windspeed: 0.025554485971880012\n",
      "hour_bef_humidity: 0.03701949400517842\n",
      "hour_bef_visibility: 0.03322718697564536\n",
      "hour_bef_ozone: 0.036345174143937085\n",
      "hour_bef_pm10: 0.032032037330242145\n",
      "hour_bef_pm2.5: 0.02044949402645348\n"
     ]
    }
   ],
   "source": [
    "for c, i in zip(X_train.columns, model.feature_importances_):\n",
    "\tprint(f\"{c}: {i}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 변수 제거"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "우선 id는 예측에 의미가 없다. 따라서 id를 제외한 데이터를 생성해야 한다. 또한 test 역시 train과 동일한 feature를 가져야 하기에 id를 제외한다. 그 외에도 위 결과를 보며 필요 없는 것들을 제거해본다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor(criterion='mse')"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1 = train.drop(['id', 'hour_bef_precipitation', 'count'], axis=1)\n",
    "test_1 = test.drop(['id', 'hour_bef_precipitation'], axis=1)\n",
    "\n",
    "model_1 = RandomForestRegressor(criterion='mse')\n",
    "model_1.fit(X_train_1, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "pred_1 = model_1.predict(test_1)\n",
    "submission_1 = pd.read_csv('.data/submission.csv')\n",
    "submission_1['count'] = pred_1\n",
    "submission_1.to_csv('sub_1.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 하이퍼파라미터 / GridSearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "하이퍼파라미터 튜닝은 정지규칙 값들을 설정하는 것을 의미한다. 의사결정나무에는 정지규칙(stopping criteria)라는 개념이 있다.\n",
    "\n",
    "- **최대 깊이(max_depth)**\n",
    "\t- 최대로 내려갈 수 있는 depth\n",
    "    - 작을수록 트리는 작아짐\n",
    "- **최소 노드크기(min_samples_split)**\n",
    "\t- 노드를 분할하기 위한 데이터 수\n",
    "\t- 해당 노드에 이 값보다 작은 확률변수 수가 있다면 멈춤\n",
    "    - 작을수록 트리는 커짐\n",
    "-  **최소 향상도(min_impurity_split)**\n",
    "\t- 노드를 분할하기 위한 최소 향상도\n",
    "    - 향상도가 설정값 이하라면 더 이상 분할하지 않음\n",
    "    - 작을수록 트리는 커짐\n",
    "- **비용 복잡도(cost-complexity)**\n",
    "\t- 트리가 커지는 것에 대해 패널티 계수를 설정해서 불순도와 트리가 커지는 것에 대해 복잡도를 계산하는 것\n",
    "\n",
    "이와 같이 정지규칙들을 종합적으로 고려해 최적의 조건값을 설정할 수 있다. 이를 하이퍼파라미터 튜닝이라고 한다.\n",
    "\n",
    "이러한 하이퍼파라미터 튜닝의 방법 중 하나가 **GridSearch**인데 완전 탐색으로 최적의 파라미터를 찾는 방법이다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "48 fits failed out of a total of 192.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.75647646 0.75812708 0.75787827 0.75661056 0.7540346  0.75555191\n",
      " 0.75534323 0.75447672 0.75154777 0.75206547 0.75141337 0.75096117\n",
      " 0.74704244 0.74832709 0.74808169 0.74752902 0.75638899 0.7580104\n",
      " 0.75821152 0.75771331 0.75455494 0.75599567 0.75582473 0.7554405\n",
      " 0.75110771 0.75162759 0.75152435 0.7510551  0.74841863 0.74951234\n",
      " 0.74960576 0.74873147 0.75750259 0.7594217  0.75964469 0.75872013\n",
      " 0.7555459  0.75727819 0.75744485 0.7564678  0.75248564 0.75301819\n",
      " 0.75318358 0.75253645 0.74865231 0.74946372 0.74960135 0.74901781\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\delphinus\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   count\n",
      "0   0   96.07\n",
      "1   1  216.50\n",
      "2   2   90.96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train = pd.read_csv(\".data/train.csv\")\n",
    "test = pd.read_csv(\".data/test.csv\")\n",
    "\n",
    "train.interpolate(inplace=True)\n",
    "test.fillna(0, inplace=True)\n",
    "\n",
    "X_train = train.drop(['count', 'id', 'hour_bef_pm2.5', 'hour_bef_precipitation'], axis=1)\n",
    "Y_train = train['count']\n",
    "test = test.drop(['id', 'hour_bef_pm2.5', 'hour_bef_precipitation'], axis=1)\n",
    "\n",
    "model = RandomForestRegressor(criterion='mse', random_state=2020)\n",
    "\n",
    "params = {\n",
    "\t'n_estimators':[200, 300, 400, 500],\n",
    "    'max_features':[5, 6, 7, 8],\n",
    "    'min_samples_leaf':[1, 3, 4, 5]\n",
    "}\n",
    "\n",
    "greedy_CV = GridSearchCV(model, param_grid=params, cv=3, n_jobs=-1)\n",
    "greedy_CV.fit(X_train, Y_train)\n",
    "\n",
    "pred = greedy_CV.predict(test)\n",
    "submission = pd.read_csv('.data/submission.csv')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "submission['count'] = np.round(pred, 2)\n",
    "print(submission.head(3))\n",
    "submission.to_csv('sub.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}