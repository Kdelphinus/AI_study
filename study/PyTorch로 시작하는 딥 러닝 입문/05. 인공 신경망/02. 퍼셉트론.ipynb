{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. 퍼셉트론(Perceptron)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "퍼셉트론은 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘입니다. 퍼셉트론은 신경 세포 뉴런의 동작과 유사합니다. 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상 크기를 가지면 축삭돌기를 통해서 신호를 전달합니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/perceptrin1_final.PNG\">\n",
    "\n",
    "마찬가지로 퍼셉트론도 입력값과 출력값이 존재합니다. 위 사진에서 $x$는 입력값, $W$는 가중치, $y$는 출력값입니다. 그림 안의 원은 인공 뉴런에 해당합니다. 입력값 $x$는 각각의 가중치 $W$와 함께 종착지인 인공 뉴런에게 전달되고 있습니다.\n",
    "\n",
    "각각의 입력값에는 각각의 가중치가 존재합니다. 그리고 가중치의 값이 클수록 해당 입력 값이 중요하다는 것을 의미합니다. \n",
    "\n",
    "각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치를 넘으면 인공 뉴런은 출력 신호로 1을 출력하고 그렇지 않으면 0을 출력합니다. 이러한 함수를 계단 함수(step function)라고 하며, 아래는 계단 함수의 예시입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24987/step_function.PNG\">\n",
    "\n",
    "이때 계단 함수에 사용된 임계치값을 보통 $\\theta$로 표현합니다. 이를 식으로 쓰면 다음과 같습니다.\n",
    "\n",
    "$$if\\;\\sum_{i}^nW_ix_i \\ge \\theta \\rightarrow y = 1$$\n",
    "$$if\\;\\sum_{i}^nW_ix_i < \\theta \\rightarrow y = 0$$\n",
    "\n",
    "단 위 식에서 임계치를 좌변으로 넘기고 $b$(bias)로 표현할 수도 있습니다. 편향 $b$ 또한 퍼셉트론의 입력으로 사용됩니다. 보통 표현할 때는 입력값이 1로 고정되고 편향 $b$가 곱해지는 변수로 표현됩니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/perceptron2_final.PNG\">\n",
    "\n",
    "$$if\\;\\sum_{i}^nW_ix_i + b \\ge 0 \\rightarrow y = 1$$\n",
    "$$if\\;\\sum_{i}^nW_ix_i + b < 0 \\rightarrow y = 0$$\n",
    "\n",
    "가중치 $W$와 편향 $b$는 딥 러닝이 최적화하기 위하여 찾아야 할 값들입니다.\n",
    "\n",
    "이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)라고 합니다. 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용했지만, 그 뒤 발전된 신경망은 시그모이드 함수. 소프트맥수 함수 등 다양한 활성화 함수를 쓰기 시작했습니다. \n",
    "\n",
    "예를 들어, 활성화 함수를 계단 함수에서 시그모이드 함수로 바꾸면 퍼셉트론이 곧 classfication을 수행하는 로지스틱 회귀와 동일함을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. 단층 퍼셉트론(Single-Layer Perceptron)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 예시로 본 퍼셉트론을 단층 퍼셉트론이라고 합니다. 퍼셉트론은 단층과 다층으로 나뉘는데 단층 퍼셉트론은 값을 보내는 단계와 값을 받아서 출력하는 두 단계로만 이루어집니다. 이때 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 합니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/perceptron3_final.PNG\">\n",
    "\n",
    "단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있습니다. 게이트 연산에서 쓰이는 것은 두 개의 입력값과 하나의 출력값입니다.\n",
    "\n",
    "AND 게이트의 경우에는 두 개의 입력값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 가집니다. AND 게이트를 만족하는 두 개의 가중치와 한 개의 편향값에는 여러 가지 조합이 나올 수 있다. 예를 들어 $[w_1, w_2, b] = [0.5, 0.5, -0.7]$이라고 한다면 파이썬 코드로 밑과 같이 간단하게 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def AND_gate(x1, x2):\n",
    "    w1, w2, b = 0.5, 0.5, -0.7\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "AND_gate(0, 0), AND_gate(1, 0), AND_gate(0, 1), AND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 보면 알 수 있듯이 두 개의 입력값이 모두 1일때만 출력값이 1이 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 NAND 게이트는 두 개의 입력값이 1일때만 출력값이 0이 나오고 나머지의 경우에는 출력값이 1이 나온다. 이때 가중치와 편향은 AND 게이트의 가중치와 편향에 -를 붙이면 성립한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NAND_gate(x1, x2):\n",
    "    w1, w2, b = -0.5, -0.5, 0.7\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "NAND_gate(0, 0), NAND_gate(1, 0), NAND_gate(0, 1), NAND_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번엔 두 개의 입력이 모두 0인 경우에만 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트를 구현해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def OR_gate(x1, x2):\n",
    "    w1, w2, b = 0.6, 0.6, -0.5\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "OR_gate(0, 0), OR_gate(1, 0), OR_gate(0, 1), OR_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 단층 퍼셉트론은 AND, NAND, OR 게이트를 구현할 수 있습니다. 그러나 단층 퍼셉트론은 XOR 게이트를 구현할 수 없습니다. XOR 게이트는 입력값 두 개가 서로 다른 값을 가지고 있을때만 1을 출력하고 두 입력값이 같을 때는 0을 출력합니다. 이를 구현할 수 없는 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 한해서 구현이 가능하기 때문입니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/andgraphgate.PNG\">\n",
    "<img src = \"https://wikidocs.net/images/page/24958/oragateandnandgate.PNG\">\n",
    "\n",
    "위 그림을 보면 알 수 있듯이, AND, NAND, OR 게이트는 하나의 직선으로 나누는 것이 가능합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/xorgraphandxorgate.PNG\">\n",
    "\n",
    "그러나 XOR 게이트는 위 그림처럼 하나의 직선으로 나누는 것이 불가능합니다. 즉, 단층 퍼셉트론으로 XOR 게이트는 구현이 불가합니다. 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말합니다. 사실 XOR 게이트는 직선이 아닌 곡선(비선형 영역)으로 분리하면 구현이 가능합니다.\n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/xorgate_nonlinearity.PNG\">\n",
    "\n",
    "위 그림처럼 말입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. 다층 퍼셉트론(MultiLayer Preceptron, MLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하여 만들 수 있습니다. 퍼셉트론 관점으로 층을 더 쌓으면 만들 수 있습니다. 다층 퍼셉트론은 단층 퍼셉트론과 다르게 입력층과 출력층 사이에 은닉층(hidden layer)을 추가했습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/perceptron_4image.jpg\">\n",
    "\n",
    "위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 MLP의 예입니다. 이를 코드로 구현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def XOR_gate(x1, x2):\n",
    "    return AND_gate(NAND_gate(x1, x2), OR_gate(x1, x2))\n",
    "\n",
    "\n",
    "XOR_gate(0, 0), XOR_gate(1, 0), XOR_gate(0, 1), XOR_gate(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 게이트는 은닉층 한 개로 구현이 가능했지만 다층 퍼셉트론의 본래 의미는 1개 이상의 은닉층을 가지는 퍼셉트론을 말합니다. 그렇기에 은닉층을 더 많이 추가하여 더 복잡한 문제를 풀 수도 있습니다. \n",
    "\n",
    "<img src = \"https://wikidocs.net/images/page/24958/%EC%9E%85%EC%9D%80%EC%B8%B5.PNG\">\n",
    "\n",
    "위와 같이 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 합니다. 심층 신경망은 다층 퍼셉트론뿐만 아니라 여러 변형된 다양한 신경망에서도 은닉층이 2개 이상이 되면 심층 신경망이라고 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 퍼셉트론이 가야할 정답을 참고해서 가중치와 편향을 찾았습니다. 하지만 이제는 기계가 가중치와 편향을 스스로 찾아내도록 자동화시켜야 하는데 이것이 머신 러닝에서 말하는 training 단계입니다. 앞서 선형 회귀와 로지스틱 회귀를 통해 보았듯이 손실 함수와 옵티마이저를 활용합니다. 그리고 만약 학습시키는 인공 신경망이 심층 신경망일 경우, 이를 딥 러닝(Deep Learning)이라고 합니다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168b3bbc19afd1ef550d68b948460bcb86336de7649712fa882c5012c218f57c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
