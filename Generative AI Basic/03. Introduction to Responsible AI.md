# 3. Introduction to Responsible AI

## Developing AI responsibly

> Developing responsible AI requires an understanding of the **possible issues**, **limitations**, or **unintended
consequences**

- 잠재적 문제, 한계, 의도치 않은 결과를 고려해야 함
- 왜냐하면 AI는 부적절한 의견이나 문제도 무분별하게 복제하여 증폭시킬 수 있기 때문
- 허나 적절한 AI나 그에 관한 규칙, 공식은 없다.
- 그렇기에 조직은 자체적인 AI 원칙을 만들고 지킨다.

## 공통적인 원칙

- Transparency(투명성)
- Fairness(공정성)
- Accountability(신뢰성)
- Privacy(개인 정보 보호)

- 이는 설계, 개발, 배포, 운영, 유지보수 등 모든 과정에서 적용되어야 한다.
- 이를 실현하기 위해 정의되고 반복적인 프로세스가 필요하다.
- 그리고 의사결정하는 모든 순간에서 고려와 평가가 있어야 책임감있는 AI를 만들 수 있다.

## 구글의 AI 원칙

1. Be socially beneficial(사회적으로 유익하게)
2. Avoid creating or reinforcing unfair bias(불공정한 편견을 만들거나 강화하지 않는다)
3. Be built and tested for safety(안전하게 빌드되고 테스트되어야 한다)
4. Be accountable to people(사람들에게 설명할 수 있어야 한다)
5. Incorporate privacy design principles(개인 정보 보호 적용 설계 원칙을 포함해야 한다)
6. Uphold high standards of scientific excellence(높은 수준의 과학적 우수성을 유지한다)
7. Be made available for uses that accord with these principles(이러한 원칙에 부합하는 용도로 제공되어야 한다)

- 그 외에 AI를 만들지 않을 용도
    - 전반적으로 피해를 주거가 초래할 가능성이 있는 기술
    - 인명 피해를 초래하거나 이를 직접적으로 지원하는 것을 기본 목적으로 하거나 구현하게 되는 무기나 기술
    - 정보를 수집하거나 감시용으로 사용함으로써 국제적으로 인정된 규범을 위반하는 기술
    - 국제법, 인권과 관련하여 널리 수용되는 원칙에 위배되는 기술

- 원칙 수립은 시작